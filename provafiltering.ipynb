{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'close', 'volume'], dtype='object')\n",
      "The drop ratio is 78.27298050139275 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helpermodules import memory_handling as mh\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import compute_sentiment, filtering_df, retrieve_datas, scraping_speeches, update_realtime, analysis\n",
    "from functions.update_realtime import change_time\n",
    "from functions.filtering_df import main as filtering\n",
    "from functions.analysis import main as plot\n",
    "from functions.scraping_speeches import main as scraping\n",
    "\n",
    "#######\n",
    "'''questa prima parte del codice presenta il codice che dovrebbe essere implementato \n",
    "(quello preceduto da '#') e in seguito il codice che ho utlizzato io non avendo ancora \n",
    "accesso alle funzioni, riciclando i file csv e 'pulendoli' per la task.\n",
    "Le funzioni che verranno implementate devono restituire un oggetto che abbia \n",
    "la stessa forma e caratteristiche dell'oggetto finale (evidenziato nel codice)'''\n",
    "\n",
    "yearlist = [2020,2021,2022,2023,2024]\n",
    "# df_fed = scraping(yearlist) -> ALREADY RUN, STORE IN ANOTHER FILE\n",
    "file = \"2020-2024fedspeeches.pkl\"\n",
    "helper = mh.PickleHelper.pickle_load(file)\n",
    "df_fed = helper.obj\n",
    "\n",
    "timezone1 = df_fed\n",
    "\n",
    "#df_prices = retrieve_datas(df_speech, deltabefore, deltaafter) -> ALREADY RUN\n",
    "file2 = \"2020-2024prices.pkl\"\n",
    "helper = mh.PickleHelper.pickle_load(file2)\n",
    "df = helper.obj\n",
    "timezone2 = df\n",
    "print(df.columns) \n",
    "df['date'] = df['datetime'].dt.date\n",
    "df_prices = df\n",
    "'''df['datetime'] = df.apply(\n",
    "    lambda row: row['datetime'].tz_localize('UTC').tz_convert(row['timezone']), axis=1\n",
    ")\n",
    "# Drop the 'timezone' column as it's no longer needed\n",
    "df = df.drop(columns=['timezone'])\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['datetime'] = df['datetime'] + pd.Timedelta(hours=4) # updated to the correct value\n",
    "df_prices = df #<--- OGGETTO FINALE\n",
    "timezone22 = df_prices'''\n",
    "\n",
    "\n",
    "#df_speech = computespeech()\n",
    "file3 = \"2020-2024speeches.pkl\"\n",
    "helper = mh.PickleHelper.pickle_load(file3)\n",
    "df_speech = helper.obj\n",
    "\n",
    "df_speech = df_speech[df_speech['date']>='2020-01-01']\n",
    "df_speech = df_speech.sort_values(['date','timestamp'], ascending=True) #<--- OGGETTO FINALE\n",
    "timezone3 = df_speech\n",
    "\n",
    "\n",
    "#df_sentiment = compute_sentiment()\n",
    "file4 = \"2020-2024sentiment.pkl\"\n",
    "helper = mh.PickleHelper.pickle_load(file4)\n",
    "df_sentiment = helper.obj \n",
    "\n",
    "\n",
    "############\n",
    "\n",
    "df_fed.rename(columns={'timestamp': 'opening_time'}, inplace=True)\n",
    "#update the correct timestamp for df_speech\n",
    "df_speech_final = change_time(df_speech, df_fed)\n",
    "#sorting the values\n",
    "df_speech_final = df_speech_final.sort_values(['date','timestamp'], ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define market open and close times (in ET)\n",
    "market_open = pd.to_datetime('09:30:00', format='%H:%M:%S').time()\n",
    "market_close = pd.to_datetime('16:00:00', format='%H:%M:%S').time()\n",
    "\n",
    "# Extract time from 'timestamp'\n",
    "df_speech_final['time'] = df_speech_final['timestamp'].dt.time\n",
    "\n",
    "# Filter rows where 'time' is within market hours\n",
    "df_filtered = df_speech_final[(df_speech_final['time'] >= market_open) & (df_speech_final['time'] < market_close)]\n",
    "df_speech_final = df_filtered.drop(columns=['time'])\n",
    "\n",
    "\n",
    "\n",
    "df_speech=df_speech_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speech_durations(df_speech):\n",
    "    \"\"\"\n",
    "    Calculates the duration of each speech by counting the number of rows for each unique\n",
    "    combination of 'date', 'speaker', and 'speech'.\n",
    "\n",
    "    Parameters:\n",
    "    df_speech : pandas.DataFrame\n",
    "        A dataframe containing ['date', 'timestamp', 'speaker', 'speech'] columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        A dataframe with a new 'duration' column added, indicating the length of each speech.\n",
    "    \"\"\"\n",
    "    # Ensure the 'date' column is in datetime format\n",
    "    df_speech['date'] = pd.to_datetime(df_speech['date'])\n",
    "\n",
    "    # Group by 'date', 'speaker', and 'speech' and count rows to calculate durations\n",
    "    speech_durations = df_speech.groupby(['date', 'speaker', 'title']).size().reset_index(name='duration')\n",
    "    speech_durations = speech_durations[speech_durations['duration']>=5]\n",
    "    # Merge the calculated durations back into the original DataFrame\n",
    "    df_speech = df_speech.merge(speech_durations, on=['date', 'speaker', 'title'], how='right')\n",
    "\n",
    "\n",
    "    return df_speech\n",
    "\n",
    "def find_timestart(df_speech):\n",
    "    \"\"\"\n",
    "    Identifies the earliest timestamp for each speech.\n",
    "\n",
    "    Parameters:\n",
    "    df_speech : pandas.DataFrame\n",
    "        A dataframe containing ['date', 'timestamp', 'speaker', 'speech'] columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        A dataframe containing only the first timestamp for each unique speech.\n",
    "    \"\"\"\n",
    "    df_speech['timestamp'] = pd.to_datetime(df_speech['timestamp'])\n",
    "\n",
    "    # Get the row with the minimum 'timestamp' for each group of 'date', 'speech', and 'speaker'\n",
    "    grouped_df = (\n",
    "        df_speech.loc[df_speech.groupby(['date', 'title', 'speaker'])['timestamp'].idxmin()]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_function(df_prices, df_speech, deltabefore=0, deltaafter=0):\n",
    "    \"\"\"\n",
    "    Filters df_prices by retaining only rows where 'timestamp' falls within the time range\n",
    "    of speeches in df_speech, including optional buffers before and after the speech duration.\n",
    "\n",
    "    Parameters:\n",
    "    df_prices : pandas.DataFrame\n",
    "        A dataframe containing ['date', 'datetime', 'close', 'volume'] columns.\n",
    "    df_speech : pandas.DataFrame\n",
    "        A dataframe containing ['date', 'timestamp', 'speaker', 'speech', 'duration'] columns.\n",
    "    deltabefore : int, optional\n",
    "        Time in minutes to include before the start of each speech (default is 0).\n",
    "    deltaafter : int, optional\n",
    "        Time in minutes to include after the end of each speech (default is 0).\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        A filtered dataframe containing rows from df_prices within the speech time ranges.\n",
    "    \"\"\"\n",
    "    # Ensure datetime columns are in the correct format\n",
    "    df_prices['datetime'] = pd.to_datetime(df_prices['datetime'])\n",
    "\n",
    "    # Prepare durations and select earliest timestamps\n",
    "    durations_df = calculate_speech_durations(df_speech)\n",
    "    durations_df = find_timestart(durations_df)\n",
    "    durations_df['timestamp'] = durations_df.apply(\n",
    "        lambda row: row['timestamp'].replace(year=row['date'].year, month=row['date'].month, day=row['date'].day),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Initialize list for storing filtered rows\n",
    "    filtered_rows = []\n",
    "\n",
    "    # Iterate over each speech and filter df_prices accordingly\n",
    "    for _, speech in durations_df.iterrows():\n",
    "        start_time = pd.to_datetime(speech['timestamp']) - pd.Timedelta(minutes=deltabefore)\n",
    "        duration = speech['duration']\n",
    "        end_time = pd.to_datetime(speech['timestamp']) + pd.Timedelta(minutes=duration + deltaafter)\n",
    "        print(start_time,end_time,'\\n\\n')\n",
    "        # Filter rows based on time range\n",
    "        mask = (df_prices['datetime'] >= start_time) & (df_prices['datetime'] <= end_time)\n",
    "        filtered_subset = df_prices[mask].copy()\n",
    "\n",
    "        # Add speech-related details\n",
    "        filtered_subset['title'] = speech['title']\n",
    "        filtered_subset['speaker'] = speech['speaker']\n",
    "        filtered_rows.append(filtered_subset)\n",
    "\n",
    "    # Combine filtered rows into a single dataframe     \n",
    "    filtered_df = pd.concat(filtered_rows, ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-21 13:30:00-05:00 2020-02-21 13:44:00-05:00 \n",
      "\n",
      "\n",
      "2020-02-25 15:00:00-05:00 2020-02-25 15:06:00-05:00 \n",
      "\n",
      "\n",
      "2020-05-21 12:00:00-04:00 2020-05-21 12:14:00-04:00 \n",
      "\n",
      "\n",
      "2020-11-17 13:00:00-05:00 2020-11-17 13:15:00-05:00 \n",
      "\n",
      "\n",
      "2021-02-22 15:30:00-05:00 2021-02-22 15:37:00-05:00 \n",
      "\n",
      "\n",
      "2021-02-24 13:00:00-05:00 2021-02-24 13:10:00-05:00 \n",
      "\n",
      "\n",
      "2021-03-18 10:55:00-04:00 2021-03-18 11:01:00-04:00 \n",
      "\n",
      "\n",
      "2021-04-14 14:45:00-04:00 2021-04-14 15:02:00-04:00 \n",
      "\n",
      "\n",
      "2021-05-03 13:20:00-04:00 2021-05-03 13:29:00-04:00 \n",
      "\n",
      "\n",
      "2021-08-03 13:00:00-04:00 2021-08-03 13:07:00-04:00 \n",
      "\n",
      "\n",
      "2021-09-09 12:00:00-04:00 2021-09-09 12:16:00-04:00 \n",
      "\n",
      "\n",
      "2021-09-28 12:40:00-04:00 2021-09-28 13:01:00-04:00 \n",
      "\n",
      "\n",
      "2021-10-12 10:15:00-04:00 2021-10-12 10:24:00-04:00 \n",
      "\n",
      "\n",
      "2021-11-19 10:45:00-05:00 2021-11-19 11:07:00-05:00 \n",
      "\n",
      "\n",
      "2021-11-19 12:15:00-05:00 2021-11-19 12:41:00-05:00 \n",
      "\n",
      "\n",
      "2021-11-30 13:00:00-05:00 2021-11-30 13:22:00-05:00 \n",
      "\n",
      "\n",
      "2022-09-07 13:00:00-04:00 2022-09-07 13:21:00-04:00 \n",
      "\n",
      "\n",
      "2022-09-28 10:00:00-04:00 2022-09-28 10:29:00-04:00 \n",
      "\n",
      "\n",
      "2022-10-06 12:00:00-04:00 2022-10-06 12:18:00-04:00 \n",
      "\n",
      "\n",
      "2022-10-10 12:35:00-04:00 2022-10-10 12:50:00-04:00 \n",
      "\n",
      "\n",
      "2023-02-27 10:30:00-05:00 2023-02-27 10:54:00-05:00 \n",
      "\n",
      "\n",
      "2023-04-18 12:00:00-04:00 2023-04-18 12:29:00-04:00 \n",
      "\n",
      "\n",
      "2023-04-21 15:35:00-04:00 2023-04-21 15:53:00-04:00 \n",
      "\n",
      "\n",
      "2023-05-05 12:00:00-04:00 2023-05-05 12:11:00-04:00 \n",
      "\n",
      "\n",
      "2023-05-13 09:30:00-04:00 2023-05-13 09:46:00-04:00 \n",
      "\n",
      "\n",
      "2023-05-31 12:30:00-04:00 2023-05-31 12:44:00-04:00 \n",
      "\n",
      "\n",
      "2023-10-02 12:00:00-04:00 2023-10-02 12:26:00-04:00 \n",
      "\n",
      "\n",
      "2023-10-04 09:30:00-04:00 2023-10-04 09:56:00-04:00 \n",
      "\n",
      "\n",
      "2023-10-09 12:30:00-04:00 2023-10-09 12:44:00-04:00 \n",
      "\n",
      "\n",
      "2023-10-25 15:35:00-04:00 2023-10-25 15:41:00-04:00 \n",
      "\n",
      "\n",
      "2023-12-05 15:00:00-05:00 2023-12-05 15:13:00-05:00 \n",
      "\n",
      "\n",
      "2024-02-07 11:00:00-05:00 2024-02-07 11:21:00-05:00 \n",
      "\n",
      "\n",
      "2024-02-12 09:30:00-05:00 2024-02-12 09:44:00-05:00 \n",
      "\n",
      "\n",
      "2024-03-25 09:30:00-04:00 2024-03-25 09:56:00-04:00 \n",
      "\n",
      "\n",
      "2024-04-03 15:30:00-04:00 2024-04-03 15:50:00-04:00 \n",
      "\n",
      "\n",
      "2024-05-15 14:20:00-04:00 2024-05-15 14:38:00-04:00 \n",
      "\n",
      "\n",
      "2024-05-20 09:30:00-04:00 2024-05-20 09:45:00-04:00 \n",
      "\n",
      "\n",
      "2024-07-09 12:30:00-04:00 2024-07-09 12:41:00-04:00 \n",
      "\n",
      "\n",
      "2024-07-10 13:30:00-04:00 2024-07-10 13:35:00-04:00 \n",
      "\n",
      "\n",
      "2024-09-10 11:15:00-04:00 2024-09-10 11:45:00-04:00 \n",
      "\n",
      "\n",
      "2024-09-30 12:55:00-04:00 2024-09-30 13:02:00-04:00 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/ybqxqy391fx0g8rhn62_7n1h0000gn/T/ipykernel_1875/3120347034.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_prices_final = df_prices_final.groupby(['title', 'date'], group_keys=False).apply(calc_pct_change)\n"
     ]
    }
   ],
   "source": [
    "deltabefore = 0\n",
    "deltaafter = 0 \n",
    "df_speech_final = pd.merge(\n",
    "    df_speech, \n",
    "    df_sentiment[['text_by_minute', 'finbert_score', 'speaker']], \n",
    "    on=['text_by_minute', 'speaker'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# eliminate duplicates \n",
    "df_speech_final = df_speech_final.drop_duplicates(subset='timestamp', keep='first')\n",
    "\n",
    "df_speech_final.rename(columns={'speech': 'title'}, inplace=True)\n",
    "\n",
    "\n",
    "# Filter prices based on speech data\n",
    "df_prices_final = filtering_function(df_prices, df_speech_final, deltabefore, deltaafter)\n",
    "\n",
    "\n",
    "# Calculate percentage change in price and merge with speech data\n",
    "df_prices_final.rename(columns={'datetime': 'timestamp'}, inplace=True)\n",
    "df_prices_final['timestamp'] = pd.to_datetime(df_prices_final['timestamp'])\n",
    "def calc_pct_change(group):\n",
    "    # Sort the group by timestamp\n",
    "    group = group.sort_values('timestamp')\n",
    "    \n",
    "    # Calculate pct_change on 'close'\n",
    "    group['pct_change'] = group['close'].pct_change()\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the custom function on each group defined by 'title' and 'date'\n",
    "df_prices_final = df_prices_final.groupby(['title', 'date'], group_keys=False).apply(calc_pct_change)\n",
    "df_speech_final.rename(columns={'speech':'title'}, inplace=True)\n",
    "\n",
    "\n",
    "df_speech_final['timestamp'] = df_speech_final.apply(\n",
    "    lambda row: row['timestamp'].replace(year=row['date'].year, month=row['date'].month, day=row['date'].day),\n",
    "    axis=1\n",
    ")\n",
    "df_speech_final['date'] = pd.to_datetime(df_speech_final['date'])\n",
    "df_prices_final['date'] = pd.to_datetime(df_prices_final['date'])\n",
    "\n",
    "\n",
    "#make sure they are both sorted by date\n",
    "\n",
    "df_speech_final = pd.merge(\n",
    "    df_speech_final,\n",
    "    df_prices_final[['date', 'title', 'timestamp', 'pct_change','volume','close']],\n",
    "    on=['date', 'title', 'timestamp'],\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
